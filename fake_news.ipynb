{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fake news",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "L23D2Opq_b-o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "942fac9a-de56-4507-d9e2-345dc8afc12d"
      },
      "source": [
        "import pandas as pd\n",
        "import csv\n",
        "import numpy as np\n",
        "import nltk\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import seaborn as sb\n",
        "\n",
        "test_filename = '/content/test.csv'\n",
        "train_filename = '/content/train.csv'\n",
        "valid_filename = '/content/valid.csv'\n",
        "\n",
        "train_news = pd.read_csv(train_filename)\n",
        "test_news = pd.read_csv(test_filename)\n",
        "valid_news = pd.read_csv(valid_filename)\n",
        "\n",
        "#data observation\n",
        "def data_obs():\n",
        "    print(\"training dataset size:\")\n",
        "    print(train_news.shape)\n",
        "    print(train_news.head(5))\n",
        "\n",
        "    #below dataset were used for testing and validation purposes\n",
        "    print(test_news.shape)\n",
        "    print(test_news.head(5))\n",
        "    \n",
        "    print(valid_news.shape)\n",
        "    print(valid_news.head(5))\n",
        "\n",
        "#check the data by calling below function\n",
        "data_obs()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training dataset size:\n",
            "(10240, 2)\n",
            "                                           Statement  Label\n",
            "0  Says the Annies List political group supports ...  False\n",
            "1  When did the decline of coal start? It started...   True\n",
            "2  Hillary Clinton agrees with John McCain \"by vo...   True\n",
            "3  Health care reform legislation is likely to ma...  False\n",
            "4  The economic turnaround started at the end of ...   True\n",
            "(2551, 2)\n",
            "                                           Statement  Label\n",
            "0  Building a wall on the U.S.-Mexico border will...   True\n",
            "1  Wisconsin is on pace to double the number of l...  False\n",
            "2  Says John McCain has done nothing to help the ...  False\n",
            "3  Suzanne Bonamici supports a plan that will cut...   True\n",
            "4  When asked by a reporter whether hes at the ce...  False\n",
            "(2571, 2)\n",
            "                                           Statement  Label\n",
            "0  We have less Americans working now than in the...  FALSE\n",
            "1  When Obama was sworn into office, he DID NOT u...  FALSE\n",
            "2  Says Having organizations parading as being so...  FALSE\n",
            "3     Says nearly half of Oregons children are poor.   TRUE\n",
            "4  On attacks by Republicans that various program...   TRUE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "DnCbU871mRup",
        "outputId": "fef1886f-9acd-4904-e607-3ceca761ad5d"
      },
      "source": [
        "#distribution of classes for prediction\n",
        "def create_distribution(dataFile):\n",
        "    \n",
        "    return sb.countplot(x='Label', data=dataFile, palette='hls')\n",
        "    \n",
        "#by calling below we can see that training, test and valid data seems to be failry evenly distributed between the classes\n",
        "create_distribution(train_news)\n",
        "create_distribution(test_news)\n",
        "create_distribution(valid_news)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fd397045890>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIo8pO0XmqvA",
        "outputId": "560afda6-302b-4d7a-e364-588d7983e867"
      },
      "source": [
        "#data integrity check (missing label values)\n",
        "#none of the datasets contains missing values therefore no cleaning required\n",
        "def data_qualityCheck():\n",
        "    \n",
        "    print(\"Checking data qualitites...\")\n",
        "    train_news.isnull().sum()\n",
        "    train_news.info()\n",
        "        \n",
        "    print(\"check finished.\")\n",
        "\n",
        "    #below datasets were used to \n",
        "    test_news.isnull().sum()\n",
        "    test_news.info()\n",
        "\n",
        "    valid_news.isnull().sum()\n",
        "    valid_news.info()\n",
        "\n",
        "#run the below function call to see the quality check results\n",
        "data_qualityCheck()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking data qualitites...\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10240 entries, 0 to 10239\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   Statement  10240 non-null  object\n",
            " 1   Label      10240 non-null  bool  \n",
            "dtypes: bool(1), object(1)\n",
            "memory usage: 90.1+ KB\n",
            "check finished.\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2551 entries, 0 to 2550\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   Statement  2551 non-null   object\n",
            " 1   Label      2551 non-null   bool  \n",
            "dtypes: bool(1), object(1)\n",
            "memory usage: 22.5+ KB\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2571 entries, 0 to 2570\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   Statement  2571 non-null   object\n",
            " 1   Label      2569 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 40.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLkXYSRVm1Mo"
      },
      "source": [
        "#Stemming\n",
        "def stem_tokens(tokens, stemmer):\n",
        "    stemmed = []\n",
        "    for token in tokens:\n",
        "        stemmed.append(stemmer.stem(token))\n",
        "    return stemmed\n",
        "\n",
        "#process the data\n",
        "def process_data(data,exclude_stopword=True,stem=True):\n",
        "    tokens = [w.lower() for w in data]\n",
        "    tokens_stemmed = tokens\n",
        "    tokens_stemmed = stem_tokens(tokens, eng_stemmer)\n",
        "    tokens_stemmed = [w for w in tokens_stemmed if w not in stopwords ]\n",
        "    return tokens_stemmed\n",
        "\n",
        "#creating ngrams\n",
        "#unigram \n",
        "def create_unigram(words):\n",
        "    assert type(words) == list\n",
        "    return words\n",
        "\n",
        "#bigram\n",
        "def create_bigrams(words):\n",
        "    assert type(words) == list\n",
        "    skip = 0\n",
        "    join_str = \" \"\n",
        "    Len = len(words)\n",
        "    if Len > 1:\n",
        "        lst = []\n",
        "        for i in range(Len-1):\n",
        "            for k in range(1,skip+2):\n",
        "                if i+k < Len:\n",
        "                    lst.append(join_str.join([words[i],words[i+k]]))\n",
        "    else:\n",
        "        #set it as unigram\n",
        "        lst = create_unigram(words)\n",
        "    return lst\n",
        "\n",
        "porter = PorterStemmer()\n",
        "\n",
        "def tokenizer(text):\n",
        "    return text.split()\n",
        "\n",
        "\n",
        "def tokenizer_porter(text):\n",
        "    return [porter.stem(word) for word in text.split()]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvWSnpEVoyvS",
        "outputId": "37754364-2ec0-4c8a-c19c-1d07e1b8108d"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import nltk\n",
        "import nltk.corpus \n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models.word2vec import Word2Vec\n",
        "\n",
        "#we will start with simple bag of words technique \n",
        "#creating feature vector - document term matrix\n",
        "countV = CountVectorizer()\n",
        "train_count = countV.fit_transform(train_news['Statement'].values)\n",
        "\n",
        "print(countV)\n",
        "print(train_count)\n",
        "\n",
        "#print training doc term matrix\n",
        "#we have matrix of size of (10240, 12196) by calling below\n",
        "def get_countVectorizer_stats():\n",
        "    \n",
        "    #vocab size\n",
        "    train_count.shape\n",
        "\n",
        "    #check vocabulary using below command\n",
        "    print(countV.vocabulary_)\n",
        "\n",
        "    #get feature names\n",
        "    print(countV.get_feature_names()[:25])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
            "                dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
            "                lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
            "                ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
            "                strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
            "                tokenizer=None, vocabulary=None)\n",
            "  (0, 9676)\t1\n",
            "  (0, 10988)\t1\n",
            "  (0, 1044)\t1\n",
            "  (0, 6639)\t1\n",
            "  (0, 8376)\t1\n",
            "  (0, 5115)\t1\n",
            "  (0, 10709)\t1\n",
            "  (0, 11036)\t1\n",
            "  (0, 11296)\t1\n",
            "  (0, 615)\t1\n",
            "  (0, 7728)\t1\n",
            "  (0, 3278)\t1\n",
            "  (1, 10988)\t1\n",
            "  (1, 11934)\t2\n",
            "  (1, 3434)\t1\n",
            "  (1, 3185)\t1\n",
            "  (1, 7672)\t1\n",
            "  (1, 2475)\t1\n",
            "  (1, 10425)\t1\n",
            "  (1, 6052)\t1\n",
            "  (1, 10426)\t2\n",
            "  (1, 7418)\t1\n",
            "  (1, 4860)\t1\n",
            "  (1, 11138)\t1\n",
            "  (1, 7674)\t1\n",
            "  :\t:\n",
            "  (10239, 10988)\t1\n",
            "  (10239, 7672)\t2\n",
            "  (10239, 11110)\t2\n",
            "  (10239, 5267)\t1\n",
            "  (10239, 7828)\t1\n",
            "  (10239, 7824)\t1\n",
            "  (10239, 1159)\t1\n",
            "  (10239, 12151)\t2\n",
            "  (10239, 6327)\t1\n",
            "  (10239, 6603)\t1\n",
            "  (10239, 11013)\t1\n",
            "  (10239, 11004)\t1\n",
            "  (10239, 3309)\t1\n",
            "  (10239, 12158)\t1\n",
            "  (10239, 11660)\t2\n",
            "  (10239, 799)\t1\n",
            "  (10239, 2568)\t1\n",
            "  (10239, 11622)\t1\n",
            "  (10239, 2549)\t1\n",
            "  (10239, 10660)\t1\n",
            "  (10239, 8996)\t1\n",
            "  (10239, 10918)\t1\n",
            "  (10239, 3989)\t1\n",
            "  (10239, 10594)\t1\n",
            "  (10239, 6853)\t1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ji4oAFIKqCNy"
      },
      "source": [
        "#create tf-df frequency features\n",
        "#tf-idf \n",
        "tfidfV = TfidfTransformer()\n",
        "train_tfidf = tfidfV.fit_transform(train_count)\n",
        "\n",
        "def get_tfidf_stats():\n",
        "    train_tfidf.shape\n",
        "    #get train data feature names \n",
        "    print(train_tfidf.A[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BWBCVfabqO3e"
      },
      "source": [
        "#bag of words - with n-grams\n",
        "#countV_ngram = CountVectorizer(ngram_range=(1,3),stop_words='english')\n",
        "#tfidf_ngram  = TfidfTransformer(use_idf=True,smooth_idf=True)\n",
        "\n",
        "tfidf_ngram = TfidfVectorizer(stop_words='english',ngram_range=(1,4),use_idf=True,smooth_idf=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QBV66-moqR2O"
      },
      "source": [
        "class MeanEmbeddingVectorizer(object):\n",
        "    def __init__(self, word2vec):\n",
        "        self.word2vec = word2vec\n",
        "        # if a text is empty we should return a vector of zeros\n",
        "        # with the same dimensionality as all the other vectors\n",
        "        self.dim = len(word2vec.itervalues().next())\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return np.array([\n",
        "            np.mean([self.word2vec[w] for w in words if w in self.word2vec]\n",
        "                    or [np.zeros(self.dim)], axis=0)\n",
        "            for words in X\n",
        "        ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItLD1P1TtSTK",
        "outputId": "051f1539-65f8-4184-aced-b83e098c73a8"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import  LogisticRegression\n",
        "from sklearn import svm\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix, f1_score, classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import learning_curve\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.metrics import average_precision_score\n",
        "from sklearn import metrics as metrics\n",
        "\n",
        "#string to test\n",
        "doc_new = ['obama is running for president in 2016']\n",
        "\n",
        "#first we will use bag of words techniques\n",
        "#building classifier using naive bayes \n",
        "nb_pipeline = Pipeline([('NBCV',countV),('nb_clf',MultinomialNB())])\n",
        "\n",
        "nb_pipeline.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_nb = nb_pipeline.predict(test_news['Statement'])\n",
        "np.mean(predicted_nb == test_news['Label'])\n",
        "\n",
        "#building classifier using logistic regression\n",
        "logR_pipeline = Pipeline([('LogRCV',countV),('LogR_clf',LogisticRegression())])\n",
        "\n",
        "logR_pipeline.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_LogR = logR_pipeline.predict(test_news['Statement'])\n",
        "np.mean(predicted_LogR == test_news['Label'])\n",
        "\n",
        "\n",
        "#building Linear SVM classfier\n",
        "svm_pipeline = Pipeline([('svmCV',countV),('svm_clf',svm.LinearSVC())])\n",
        "\n",
        "svm_pipeline.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_svm = svm_pipeline.predict(test_news['Statement'])\n",
        "np.mean(predicted_svm == test_news['Label'])\n",
        "\n",
        "#random forest\n",
        "random_forest = Pipeline([('rfCV',countV),('rf_clf',RandomForestClassifier(n_estimators=200,n_jobs=3))])\n",
        "    \n",
        "random_forest.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_rf = random_forest.predict(test_news['Statement'])\n",
        "np.mean(predicted_rf == test_news['Label'])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6287730301842415"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yql7H3GNuzGM"
      },
      "source": [
        "#User defined functon for K-Fold cross validatoin\n",
        "def build_confusion_matrix(classifier):\n",
        "    \n",
        "    k_fold = KFold(n_splits=5)\n",
        "    scores = []\n",
        "    confusion = np.array([[0,0],[0,0]])\n",
        "\n",
        "    for train_ind, test_ind in k_fold.split(train_news):\n",
        "        train_text = train_news.iloc[train_ind]['Statement'] \n",
        "        train_y = train_news.iloc[train_ind]['Label']\n",
        "    \n",
        "        test_text = train_news.iloc[test_ind]['Statement']\n",
        "        test_y = train_news.iloc[test_ind]['Label']\n",
        "        \n",
        "        classifier.fit(train_text,train_y)\n",
        "        predictions = classifier.predict(test_text)\n",
        "        \n",
        "        confusion += confusion_matrix(test_y,predictions)\n",
        "        score = f1_score(test_y,predictions)\n",
        "        scores.append(score)\n",
        "    \n",
        "    return (print('Total statements classified:', len(train_news)),\n",
        "    print('Score:', sum(scores)/len(scores)),\n",
        "    print('score length', len(scores)),\n",
        "    print('Confusion matrix:'),\n",
        "    print(confusion))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSyG2q8bvGxE",
        "outputId": "8633d1bf-c2af-4ad7-bc20-45550829b7ac"
      },
      "source": [
        "#K-fold cross validation for all classifiers\n",
        "build_confusion_matrix(nb_pipeline)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total statements classified: 10240\n",
            "Score: 0.66961153965076\n",
            "score length 5\n",
            "Confusion matrix:\n",
            "[[2118 2370]\n",
            " [1664 4088]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_gTtnCFvewr",
        "outputId": "f2ff97fd-af56-45dd-92bc-980af77877ba"
      },
      "source": [
        "build_confusion_matrix(logR_pipeline)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total statements classified: 10240\n",
            "Score: 0.6466692934443682\n",
            "score length 5\n",
            "Confusion matrix:\n",
            "[[2254 2234]\n",
            " [1936 3816]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kErR3GR_vmAb",
        "outputId": "75a942bf-2828-4c68-9a34-e1964a03f9cb"
      },
      "source": [
        "build_confusion_matrix(svm_pipeline)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total statements classified: 10240\n",
            "Score: 0.6104687487924283\n",
            "score length 5\n",
            "Confusion matrix:\n",
            "[[2260 2228]\n",
            " [2246 3506]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saJrBUXavqd8",
        "outputId": "14ba936f-74d4-4434-dd24-d95a53a0c79f"
      },
      "source": [
        "build_confusion_matrix(random_forest)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total statements classified: 10240\n",
            "Score: 0.702619868894328\n",
            "score length 5\n",
            "Confusion matrix:\n",
            "[[1804 2684]\n",
            " [1183 4569]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrDXvG2JwEdF",
        "outputId": "cdfc0abf-c11a-4b24-d772-0333e7a5f15d"
      },
      "source": [
        "##Now using n-grams\n",
        "#naive-bayes classifier\n",
        "nb_pipeline_ngram = Pipeline([('nb_tfidf',tfidf_ngram),('nb_clf',MultinomialNB())])\n",
        "\n",
        "nb_pipeline_ngram.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_nb_ngram = nb_pipeline_ngram.predict(test_news['Statement'])\n",
        "np.mean(predicted_nb_ngram == test_news['Label'])\n",
        "\n",
        "\n",
        "#logistic regression classifier\n",
        "logR_pipeline_ngram = Pipeline([('LogR_tfidf',tfidf_ngram),('LogR_clf',LogisticRegression(penalty=\"l2\",C=1))])\n",
        "\n",
        "logR_pipeline_ngram.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_LogR_ngram = logR_pipeline_ngram.predict(test_news['Statement'])\n",
        "np.mean(predicted_LogR_ngram == test_news['Label'])\n",
        "\n",
        "\n",
        "#linear SVM classifier\n",
        "svm_pipeline_ngram = Pipeline([('svm_tfidf',tfidf_ngram),('svm_clf',svm.LinearSVC())])\n",
        "\n",
        "svm_pipeline_ngram.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_svm_ngram = svm_pipeline_ngram.predict(test_news['Statement'])\n",
        "np.mean(predicted_svm_ngram == test_news['Label'])\n",
        "\n",
        "#random forest classifier\n",
        "random_forest_ngram = Pipeline([\n",
        "        ('rf_tfidf',tfidf_ngram),\n",
        "        ('rf_clf',RandomForestClassifier(n_estimators=300,n_jobs=3))\n",
        "        ])\n",
        "    \n",
        "random_forest_ngram.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_rf_ngram = random_forest_ngram.predict(test_news['Statement'])\n",
        "np.mean(predicted_rf_ngram == test_news['Label'])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6032928263426107"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubpi-CCaxypr",
        "outputId": "8db38f87-b148-4b3b-b816-97fc5980d346"
      },
      "source": [
        "#K-fold cross validation for all classifiers\n",
        "build_confusion_matrix(nb_pipeline_ngram)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total statements classified: 10240\n",
            "Score: 0.7224053159841455\n",
            "score length 5\n",
            "Confusion matrix:\n",
            "[[ 758 3730]\n",
            " [ 390 5362]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "db5GtGV8x7VH",
        "outputId": "ce8a5804-7e55-4140-e828-6742de8f093f"
      },
      "source": [
        "build_confusion_matrix(logR_pipeline_ngram)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total statements classified: 10240\n",
            "Score: 0.7044355553757985\n",
            "score length 5\n",
            "Confusion matrix:\n",
            "[[1580 2908]\n",
            " [1043 4709]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YqrNcDe3y38f",
        "outputId": "29f202fb-7887-4555-cd2b-cdcea0ce34e4"
      },
      "source": [
        "build_confusion_matrix(svm_pipeline_ngram)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total statements classified: 10240\n",
            "Score: 0.6790920142902143\n",
            "score length 5\n",
            "Confusion matrix:\n",
            "[[2016 2472]\n",
            " [1524 4228]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pe3jDzQry_T0",
        "outputId": "f0f0b34a-137d-4a07-96c5-f0d6f9336b65"
      },
      "source": [
        "build_confusion_matrix(random_forest_ngram)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total statements classified: 10240\n",
            "Score: 0.6586769261799301\n",
            "score length 5\n",
            "Confusion matrix:\n",
            "[[1991 2497]\n",
            " [1701 4051]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None, None, None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7lcQIwTX0yK3",
        "outputId": "2ccc27ab-97ab-4a37-d000-c87682c5310a"
      },
      "source": [
        "print(classification_report(test_news['Label'], predicted_nb_ngram))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.72      0.19      0.30      1169\n",
            "        True       0.58      0.94      0.71      1382\n",
            "\n",
            "    accuracy                           0.59      2551\n",
            "   macro avg       0.65      0.56      0.51      2551\n",
            "weighted avg       0.64      0.59      0.52      2551\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TVckTxM1FAL",
        "outputId": "a7b8e963-30b2-4f4b-d362-16a3c349439a"
      },
      "source": [
        "print(classification_report(test_news['Label'], predicted_LogR_ngram))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.64      0.39      0.49      1169\n",
            "        True       0.61      0.81      0.70      1382\n",
            "\n",
            "    accuracy                           0.62      2551\n",
            "   macro avg       0.62      0.60      0.59      2551\n",
            "weighted avg       0.62      0.62      0.60      2551\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moE0m4ow1NYn",
        "outputId": "ca537f2f-cc48-4372-fc66-58f74084c0e3"
      },
      "source": [
        "print(classification_report(test_news['Label'], predicted_svm_ngram))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.61      0.47      0.53      1169\n",
            "        True       0.62      0.74      0.68      1382\n",
            "\n",
            "    accuracy                           0.62      2551\n",
            "   macro avg       0.61      0.61      0.60      2551\n",
            "weighted avg       0.62      0.62      0.61      2551\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6XIwbN01XWm",
        "outputId": "db538603-eff5-4fb9-b3ae-d68ce3ea1324"
      },
      "source": [
        "print(classification_report(test_news['Label'], predicted_rf_ngram))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.58      0.48      0.53      1169\n",
            "        True       0.62      0.71      0.66      1382\n",
            "\n",
            "    accuracy                           0.60      2551\n",
            "   macro avg       0.60      0.60      0.59      2551\n",
            "weighted avg       0.60      0.60      0.60      2551\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGHiiZQl1gIW",
        "outputId": "6219c8dc-e28f-4b17-fdee-ec1c497e5f1c"
      },
      "source": [
        "test_news['Label'].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2551,)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_xSGnR-1mpY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c06496a-bd37-43ba-9731-77b9d0e2271c"
      },
      "source": [
        "\"\"\"\n",
        "Out of all the models fitted, we would take 2 best performing model. we would call them candidate models\n",
        "from the confusion matrix, we can see that random forest and logistic regression are best performing \n",
        "in terms of precision and recall (take a look into false positive and true negative counts which appeares\n",
        "to be low compared to rest of the models)\n",
        "\"\"\"\n",
        "\n",
        "#grid-search parameter optimization\n",
        "#random forest classifier parameters\n",
        "parameters = {'rf_tfidf__ngram_range': [(1, 1), (1, 2),(1,3),(1,4),(1,5)],\n",
        "               'rf_tfidf__use_idf': (True, False),\n",
        "               'rf_clf__max_depth': (1,2,3,4,5,6,7,8,9,10,11,12,13,14,15)\n",
        "}\n",
        "\n",
        "gs_clf = GridSearchCV(random_forest_ngram, parameters, n_jobs=-1)\n",
        "gs_clf = gs_clf.fit(train_news['Statement'][:10000],train_news['Label'][:10000])\n",
        "\n",
        "gs_clf.best_score_\n",
        "gs_clf.best_params_\n",
        "gs_clf.cv_results_\n",
        "\n",
        "#logistic regression parameters\n",
        "parameters = {'LogR_tfidf__ngram_range': [(1, 1), (1, 2),(1,3),(1,4),(1,5)],\n",
        "               'LogR_tfidf__use_idf': (True, False),\n",
        "               'LogR_tfidf__smooth_idf': (True, False)\n",
        "}\n",
        "\n",
        "gs_clf = GridSearchCV(logR_pipeline_ngram, parameters, n_jobs=-1)\n",
        "gs_clf = gs_clf.fit(train_news['Statement'][:10000],train_news['Label'][:10000])\n",
        "\n",
        "gs_clf.best_score_\n",
        "gs_clf.best_params_\n",
        "gs_clf.cv_results_"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([0.5335783 , 0.43563986, 0.49761553, 0.43352704, 1.6563477 ,\n",
              "        1.78655815, 1.59093828, 1.66915088, 2.51540923, 2.93279033,\n",
              "        2.2748045 , 3.06595411, 2.90944996, 3.73267937, 2.98615289,\n",
              "        3.70639367, 3.67781048, 4.44682856, 3.99305201, 4.26709337]),\n",
              " 'mean_score_time': array([0.05822487, 0.05589995, 0.06027188, 0.05972161, 0.09583383,\n",
              "        0.09787092, 0.09684906, 0.0883059 , 0.12005529, 0.11689844,\n",
              "        0.12203012, 0.12126141, 0.15954876, 0.14570651, 0.15293941,\n",
              "        0.14581213, 0.17061439, 0.16733456, 0.17930965, 0.14879241]),\n",
              " 'mean_test_score': array([0.6046, 0.6106, 0.6055, 0.6106, 0.6142, 0.6105, 0.614 , 0.6105,\n",
              "        0.6149, 0.6103, 0.6162, 0.6103, 0.6165, 0.6097, 0.6159, 0.6097,\n",
              "        0.616 , 0.6093, 0.6151, 0.6093]),\n",
              " 'param_LogR_tfidf__ngram_range': masked_array(data=[(1, 1), (1, 1), (1, 1), (1, 1), (1, 2), (1, 2), (1, 2),\n",
              "                    (1, 2), (1, 3), (1, 3), (1, 3), (1, 3), (1, 4), (1, 4),\n",
              "                    (1, 4), (1, 4), (1, 5), (1, 5), (1, 5), (1, 5)],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_LogR_tfidf__smooth_idf': masked_array(data=[True, True, False, False, True, True, False, False,\n",
              "                    True, True, False, False, True, True, False, False,\n",
              "                    True, True, False, False],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'param_LogR_tfidf__use_idf': masked_array(data=[True, False, True, False, True, False, True, False,\n",
              "                    True, False, True, False, True, False, True, False,\n",
              "                    True, False, True, False],\n",
              "              mask=[False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False, False, False, False, False,\n",
              "                    False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'LogR_tfidf__ngram_range': (1, 1),\n",
              "   'LogR_tfidf__smooth_idf': True,\n",
              "   'LogR_tfidf__use_idf': True},\n",
              "  {'LogR_tfidf__ngram_range': (1, 1),\n",
              "   'LogR_tfidf__smooth_idf': True,\n",
              "   'LogR_tfidf__use_idf': False},\n",
              "  {'LogR_tfidf__ngram_range': (1, 1),\n",
              "   'LogR_tfidf__smooth_idf': False,\n",
              "   'LogR_tfidf__use_idf': True},\n",
              "  {'LogR_tfidf__ngram_range': (1, 1),\n",
              "   'LogR_tfidf__smooth_idf': False,\n",
              "   'LogR_tfidf__use_idf': False},\n",
              "  {'LogR_tfidf__ngram_range': (1, 2),\n",
              "   'LogR_tfidf__smooth_idf': True,\n",
              "   'LogR_tfidf__use_idf': True},\n",
              "  {'LogR_tfidf__ngram_range': (1, 2),\n",
              "   'LogR_tfidf__smooth_idf': True,\n",
              "   'LogR_tfidf__use_idf': False},\n",
              "  {'LogR_tfidf__ngram_range': (1, 2),\n",
              "   'LogR_tfidf__smooth_idf': False,\n",
              "   'LogR_tfidf__use_idf': True},\n",
              "  {'LogR_tfidf__ngram_range': (1, 2),\n",
              "   'LogR_tfidf__smooth_idf': False,\n",
              "   'LogR_tfidf__use_idf': False},\n",
              "  {'LogR_tfidf__ngram_range': (1, 3),\n",
              "   'LogR_tfidf__smooth_idf': True,\n",
              "   'LogR_tfidf__use_idf': True},\n",
              "  {'LogR_tfidf__ngram_range': (1, 3),\n",
              "   'LogR_tfidf__smooth_idf': True,\n",
              "   'LogR_tfidf__use_idf': False},\n",
              "  {'LogR_tfidf__ngram_range': (1, 3),\n",
              "   'LogR_tfidf__smooth_idf': False,\n",
              "   'LogR_tfidf__use_idf': True},\n",
              "  {'LogR_tfidf__ngram_range': (1, 3),\n",
              "   'LogR_tfidf__smooth_idf': False,\n",
              "   'LogR_tfidf__use_idf': False},\n",
              "  {'LogR_tfidf__ngram_range': (1, 4),\n",
              "   'LogR_tfidf__smooth_idf': True,\n",
              "   'LogR_tfidf__use_idf': True},\n",
              "  {'LogR_tfidf__ngram_range': (1, 4),\n",
              "   'LogR_tfidf__smooth_idf': True,\n",
              "   'LogR_tfidf__use_idf': False},\n",
              "  {'LogR_tfidf__ngram_range': (1, 4),\n",
              "   'LogR_tfidf__smooth_idf': False,\n",
              "   'LogR_tfidf__use_idf': True},\n",
              "  {'LogR_tfidf__ngram_range': (1, 4),\n",
              "   'LogR_tfidf__smooth_idf': False,\n",
              "   'LogR_tfidf__use_idf': False},\n",
              "  {'LogR_tfidf__ngram_range': (1, 5),\n",
              "   'LogR_tfidf__smooth_idf': True,\n",
              "   'LogR_tfidf__use_idf': True},\n",
              "  {'LogR_tfidf__ngram_range': (1, 5),\n",
              "   'LogR_tfidf__smooth_idf': True,\n",
              "   'LogR_tfidf__use_idf': False},\n",
              "  {'LogR_tfidf__ngram_range': (1, 5),\n",
              "   'LogR_tfidf__smooth_idf': False,\n",
              "   'LogR_tfidf__use_idf': True},\n",
              "  {'LogR_tfidf__ngram_range': (1, 5),\n",
              "   'LogR_tfidf__smooth_idf': False,\n",
              "   'LogR_tfidf__use_idf': False}],\n",
              " 'rank_test_score': array([20,  9, 19,  9,  7, 11,  8, 11,  6, 13,  2, 13,  1, 15,  4, 15,  3,\n",
              "        17,  5, 17], dtype=int32),\n",
              " 'split0_test_score': array([0.6135, 0.617 , 0.6125, 0.617 , 0.619 , 0.617 , 0.6175, 0.617 ,\n",
              "        0.6205, 0.6175, 0.621 , 0.6175, 0.6175, 0.6155, 0.6175, 0.6155,\n",
              "        0.614 , 0.615 , 0.6115, 0.615 ]),\n",
              " 'split1_test_score': array([0.618 , 0.6205, 0.6185, 0.6205, 0.6245, 0.623 , 0.625 , 0.623 ,\n",
              "        0.6245, 0.6165, 0.624 , 0.6165, 0.623 , 0.613 , 0.6205, 0.613 ,\n",
              "        0.622 , 0.6135, 0.619 , 0.6135]),\n",
              " 'split2_test_score': array([0.5945, 0.603 , 0.596 , 0.603 , 0.6025, 0.6015, 0.605 , 0.6015,\n",
              "        0.604 , 0.6045, 0.608 , 0.6045, 0.609 , 0.603 , 0.607 , 0.603 ,\n",
              "        0.6065, 0.601 , 0.609 , 0.601 ]),\n",
              " 'split3_test_score': array([0.599 , 0.608 , 0.5995, 0.608 , 0.6105, 0.605 , 0.6105, 0.605 ,\n",
              "        0.6125, 0.606 , 0.615 , 0.606 , 0.617 , 0.611 , 0.616 , 0.611 ,\n",
              "        0.621 , 0.6115, 0.618 , 0.6115]),\n",
              " 'split4_test_score': array([0.598 , 0.6045, 0.601 , 0.6045, 0.6145, 0.606 , 0.612 , 0.606 ,\n",
              "        0.613 , 0.607 , 0.613 , 0.607 , 0.616 , 0.606 , 0.6185, 0.606 ,\n",
              "        0.6165, 0.6055, 0.618 , 0.6055]),\n",
              " 'std_fit_time': array([0.01348422, 0.0207831 , 0.01601602, 0.01321925, 0.03660759,\n",
              "        0.04866055, 0.09668435, 0.04440202, 0.20013181, 0.11579853,\n",
              "        0.05510788, 0.08249426, 0.10805343, 0.1975633 , 0.16081669,\n",
              "        0.19315144, 0.31285131, 0.24718618, 0.15381676, 0.68327618]),\n",
              " 'std_score_time': array([0.00070614, 0.00097669, 0.00414188, 0.00365156, 0.00154471,\n",
              "        0.00502393, 0.00191368, 0.00518873, 0.01073179, 0.00327847,\n",
              "        0.00531524, 0.00620263, 0.00558034, 0.00396707, 0.00516537,\n",
              "        0.00451158, 0.00835192, 0.01083425, 0.00448479, 0.0295719 ]),\n",
              " 'std_test_score': array([0.00933488, 0.0069383 , 0.00853815, 0.0069383 , 0.00748064,\n",
              "        0.00812404, 0.0067897 , 0.00812404, 0.00709507, 0.00553715,\n",
              "        0.00570614, 0.00553715, 0.00447214, 0.00457821, 0.00468402,\n",
              "        0.00457821, 0.00557674, 0.00525928, 0.00405463, 0.00525928])}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UqhEn2OK25GO",
        "outputId": "b88c36b3-230e-4630-9e33-fad95c773073"
      },
      "source": [
        "#running both random forest and logistic regression models again with best parameter found with GridSearch method\n",
        "random_forest_final = Pipeline([\n",
        "        ('rf_tfidf',TfidfVectorizer(stop_words='english',ngram_range=(1,3),use_idf=True,smooth_idf=True)),\n",
        "        ('rf_clf',RandomForestClassifier(n_estimators=300,n_jobs=3,max_depth=10))\n",
        "        ])\n",
        "    \n",
        "random_forest_final.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_rf_final = random_forest_final.predict(test_news['Statement'])\n",
        "np.mean(predicted_rf_final == test_news['Label'])\n",
        "print(metrics.classification_report(test_news['Label'], predicted_rf_final))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.33      0.00      0.00      1169\n",
            "        True       0.54      1.00      0.70      1382\n",
            "\n",
            "    accuracy                           0.54      2551\n",
            "   macro avg       0.44      0.50      0.35      2551\n",
            "weighted avg       0.45      0.54      0.38      2551\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pAek7WvM3wcm",
        "outputId": "99f2402d-9c9a-4bdb-c39b-efbe76336416"
      },
      "source": [
        "logR_pipeline_final = Pipeline([\n",
        "        #('LogRCV',countV_ngram),\n",
        "        ('LogR_tfidf',TfidfVectorizer(stop_words='english',ngram_range=(1,5),use_idf=True,smooth_idf=False)),\n",
        "        ('LogR_clf',LogisticRegression(penalty=\"l2\",C=1))\n",
        "        ])\n",
        "\n",
        "logR_pipeline_final.fit(train_news['Statement'],train_news['Label'])\n",
        "predicted_LogR_final = logR_pipeline_final.predict(test_news['Statement'])\n",
        "np.mean(predicted_LogR_final == test_news['Label'])\n",
        "#accuracy = 0.62\n",
        "print(metrics.classification_report(test_news['Label'], predicted_LogR_final))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       False       0.64      0.38      0.48      1169\n",
            "        True       0.61      0.82      0.70      1382\n",
            "\n",
            "    accuracy                           0.62      2551\n",
            "   macro avg       0.62      0.60      0.59      2551\n",
            "weighted avg       0.62      0.62      0.60      2551\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhCRYNW936Bo"
      },
      "source": [
        "\"\"\"\n",
        "by running both random forest and logistic regression with GridSearch's best parameter estimation, we found that for random \n",
        "forest model with n-gram has better accuracty than with the parameter estimated. The logistic regression model with best parameter \n",
        "has almost similar performance as n-gram model so logistic regression will be out choice of model for prediction.\n",
        "\"\"\"\n",
        "\n",
        "#saving best model to the disk\n",
        "model_file = 'final_model.sav'\n",
        "pickle.dump(logR_pipeline_ngram,open(model_file,'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWXzrxCF4C1H"
      },
      "source": [
        "#Plotting learning curve\n",
        "def plot_learning_curve(pipeline,title):\n",
        "    size = 10000\n",
        "    cv = KFold(size, shuffle=True)\n",
        "    \n",
        "    X = train_news[\"Statement\"]\n",
        "    y = train_news[\"Label\"]\n",
        "    \n",
        "    pl = pipeline\n",
        "    pl.fit(X,y)\n",
        "    \n",
        "    train_sizes, train_scores, test_scores = learning_curve(pl, X, y, n_jobs=-1, cv=cv, train_sizes=np.linspace(.1, 1.0, 5), verbose=0)\n",
        "       \n",
        "    train_scores_mean = np.mean(train_scores, axis=1)\n",
        "    train_scores_std = np.std(train_scores, axis=1)\n",
        "    test_scores_mean = np.mean(test_scores, axis=1)\n",
        "    test_scores_std = np.std(test_scores, axis=1)\n",
        "     \n",
        "    plt.figure()\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"best\")\n",
        "    plt.xlabel(\"Training examples\")\n",
        "    plt.ylabel(\"Score\")\n",
        "    plt.gca().invert_yaxis()\n",
        "    \n",
        "    # box-like grid\n",
        "    plt.grid()\n",
        "    \n",
        "    # plot the std deviation as a transparent range at each training set size\n",
        "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, alpha=0.1, color=\"r\")\n",
        "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
        "    \n",
        "    # plot the average training and test score lines at each training set size\n",
        "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\", label=\"Training score\")\n",
        "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\", label=\"Cross-validation score\")\n",
        "    \n",
        "    # sizes the window for readability and displays the plot\n",
        "    # shows error from 0 to 1.1\n",
        "    plt.ylim(-.1,1.1)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6niriKp_dsdl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "83d58c23-74d1-4346-957b-a45d0761ff10"
      },
      "source": [
        "#below command will plot learing curves for each of the classifiers\n",
        "plot_learning_curve(logR_pipeline_ngram,\"LogisticRegression Classifier\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-a94c4c270eb8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#below command will plot learing curves for each of the classifiers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_learning_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogR_pipeline_ngram\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"LogisticRegression Classifier\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-16-97bcb90bb491>\u001b[0m in \u001b[0;36mplot_learning_curve\u001b[0;34m(pipeline, title)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtrain_sizes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearning_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mtrain_scores_mean\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mlearning_curve\u001b[0;34m(estimator, X, y, groups, train_sizes, cv, scoring, exploit_incremental_learning, n_jobs, pre_dispatch, verbose, shuffle, random_state, error_score, return_times)\u001b[0m\n\u001b[1;32m   1254\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1255\u001b[0m             error_score=error_score, return_times=return_times)\n\u001b[0;32m-> 1256\u001b[0;31m             for train, test in train_test_proportions)\n\u001b[0m\u001b[1;32m   1257\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1258\u001b[0m         \u001b[0mn_cv_folds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mn_unique_ticks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8juTsfEsN23"
      },
      "source": [
        "def plot_PR_curve(classifier):\n",
        "    \n",
        "    precision, recall, thresholds = precision_recall_curve(test_news['Label'], classifier)\n",
        "    average_precision = average_precision_score(test_news['Label'], classifier)\n",
        "    \n",
        "    plt.step(recall, precision, color='b', alpha=0.2,\n",
        "             where='post')\n",
        "    plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
        "                     color='b')\n",
        "    \n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.title('2-class Random Forest Precision-Recall curve: AP={0:0.2f}'.format(\n",
        "              average_precision))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "A5oV_XZZsWLs",
        "outputId": "1eca32b8-06a1-45eb-85ce-065751eb79d1"
      },
      "source": [
        "plot_PR_curve(predicted_LogR_ngram)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "FM1qUH-fuzYV",
        "outputId": "146d85d7-4aa2-458c-ecf3-d871ebb53b0f"
      },
      "source": [
        "plot_PR_curve(predicted_rf_ngram)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}